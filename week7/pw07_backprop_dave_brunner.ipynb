{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88de7e72-0814-405b-8c2c-cefa78d66dc0",
   "metadata": {},
   "source": [
    "### Model\n",
    "\n",
    "A Model here consists of a succession of layers.\n",
    "\n",
    "Each layer is implemented as a class with the following API-methods:\n",
    "\n",
    "`forward(torch.tensor)`: Computes the forward pass through the layer, i.e. $x\\rightarrow a$<br> and keeps the information needed for computing the backward pass as member variables. \n",
    "`backward(torch.tensor)`: Computes the backward pass through the layer in form of the derivatives, i.e. $da \\rightarrow dx$. On the fly, it also computes the derivatives w.r.t. the parameters of the layer and keeps them as member variables. It assumes that `forward` method has been run before. <br>\n",
    "`update(lr)`: Updates the parameters of the layer in accordance with vanilla gradient descent and scalar learning rate `lr`. It assumes that the `forward` and the `backward`-pass has been run before.  \n",
    "\n",
    "The tensors defined as inputs to the `forward`/`backward`-method are two dimensional with the sample index in the first and the the feature index in the second dimension. \n",
    "\n",
    "For fully connected layers with activation function $s(\\cdot)$ the formulas are given as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bdbdc5-d75a-416b-a5df-dfd3ef1fca05",
   "metadata": {},
   "source": [
    "__Forward path:__\n",
    "\n",
    "$X_{i,j}$: Tensor with shape $(n_b,n_x)$ where $n_b$ is the number of samples in the batch and $n_x$ the number of input features (for MNIST: 784).\n",
    "\n",
    "$Z_{i,j} = \\sum_k X_{i,k} W_{j,k} \\qquad (Z = X \\cdot W^T + b)$ $\\qquad$ ($W$ a tensor of shape $(n_h,n_x)$)\n",
    "\n",
    "$A_{i,j} = s(Z_{i,j}) \\qquad\\qquad (A = s(Z))$\n",
    "\n",
    "__Backward path:__ (with $n_b$ the number of samples in a batch)\n",
    "\n",
    "$dx_{i,k} = \\frac{\\partial L}{\\partial x_{i,k}} = \\sum_j \\frac{\\partial L}{\\partial a_{i,j}} \\frac{\\partial a_{i,j}}{\\partial x_{i,k}} = \\sum_j da_{i,j} s^\\prime(z_{i,j})\\cdot \\frac{\\partial z_{i,j}}{\\partial x_{i,k}} = \\sum_j da_{i,j} s^\\prime(z_{i,j}) W_{j,k}$<br>\n",
    "\n",
    "$dW_{j,k} = \\frac{\\partial L}{\\partial W_{j,k}} = \\frac{1}{n_b}\\sum_{i,l} dA_{i,l}\\frac{\\partial A_{i,l}}{\\partial W_{j,k}} = \\frac{1}{n_b}\\sum_{i,l} dA_{i,l} s^\\prime(Z_{i,l}) \\delta_{j,l} X_{i,k} = \\frac{1}{n_b}\\sum_{i} dA_{i,j} s^\\prime(Z_{i,j}) X_{i,k} $<br>\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad958e2-bb1e-493f-9c4d-40514e20c479",
   "metadata": {},
   "source": [
    "__Parameter Initialisation__ \n",
    "\n",
    "The parameters need to be initialised which will be a topic later in the course. For now use the following rules: \n",
    "* weights normally distributed with mean $0$ and stdev $1/\\sqrt{n_h}$\n",
    "* bias initialized with zero values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6d7916-88e9-4cc9-91e8-ec600741370d",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### <span style=\"color:red\">Important Note on the Implementation</span>\n",
    "\n",
    "Make sure that all the tensors used anywhere in the model components below have `requires_grad=False`.\n",
    "Autograd functionality is not allowed for computing the gradients. - Autograd will be used below for testing whether your implementation is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "7d3c3737-73dc-481a-8cf0-afb3657ca3cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T14:45:23.427727Z",
     "start_time": "2024-04-08T14:45:23.426167Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eae0f20-6928-481d-96b2-02cbfa298760",
   "metadata": {},
   "source": [
    "### Linear Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "c81dc286-9543-4278-a174-6fbba6be026f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T14:45:23.469678Z",
     "start_time": "2024-04-08T14:45:23.466775Z"
    }
   },
   "outputs": [],
   "source": [
    "class LinearLayer():\n",
    "    def __init__(self, nx, nh):\n",
    "        \"\"\"\n",
    "        nx -- number of input features, i.e. shape of input tensors x given by (*,nb_input)\n",
    "        nh -- number of output features, i.e. shape of output tensor z given by (*,nb_hidden)\n",
    "        dw -- represents the gradient of the loss function with respect to the weights w\n",
    "        db -- represents the gradient of the loss function with respect to the bias b\n",
    "        \"\"\"\n",
    "        self.nx = nx\n",
    "        self.nh = nh\n",
    "        self.w = torch.empty(nh, nx).normal_(0, 1. / math.sqrt(self.nh))\n",
    "        self.b = torch.zeros(nh)\n",
    "        self.dw = torch.zeros_like(self.w)\n",
    "        self.db = torch.zeros_like(self.b)\n",
    "        self.x = None\n",
    "        self.dx = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Computes the forward pass through the layer\n",
    "        x -- input tensor\n",
    "        returns z \n",
    "        \"\"\"\n",
    "        self.x = x\n",
    "        return self.x.matmul(self.w.t()) + self.b\n",
    "\n",
    "    def backward(self, dz):\n",
    "        \"\"\"\n",
    "        Computes the backward pass through the layer incl. the derivatives w.r.t. input x (dx), weight w (dw) and bias b (db).\n",
    "        dz -- tensor with the backprop'd error signal with the same shape as z.         \n",
    "        returns dx\n",
    "        \"\"\"\n",
    "        assert len(dz.shape) == 2 and dz.shape[1] == self.nh\n",
    "        # Compute the gradient with respect to input x (dx)\n",
    "        self.dx = dz.matmul(self.w)\n",
    "        # Compute the gradient with respect to weight w (dw)\n",
    "        self.dw = dz.t().matmul(self.x)\n",
    "        # Compute the gradient with respect to bias b (db)\n",
    "        self.db = torch.mean(dz, dim=0)\n",
    "\n",
    "        # self.db = dz.mean(dim=0)\n",
    "\n",
    "        # Compute gradient w.r.t. weights\n",
    "        # self.dw = torch.matmul(dz.t(), self.x) / self.x.shape[0]\n",
    "        # Compute gradient w.r.t. bias\n",
    "        # self.db = torch.mean(dz, dim=0)\n",
    "        return self.dx\n",
    "\n",
    "    def update(self, lr):\n",
    "        \"\"\"\n",
    "        Updates the parameters of the model (weights w and bias b) with the gradient w.r.t. w and b and learning rate.\n",
    "        returns None\n",
    "        \"\"\"\n",
    "        self.w -= lr * self.dw\n",
    "        self.b -= lr * self.db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f9fd5b-a7b6-4a74-bd71-ab9bc1c79263",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">SHAPE TEST:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "28d46297-caf7-4b69-bc8f-9b32eb25590d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T14:45:23.474514Z",
     "start_time": "2024-04-08T14:45:23.472322Z"
    }
   },
   "outputs": [],
   "source": [
    "linear = LinearLayer(3, 4)\n",
    "assert (4, 3) == linear.w.shape\n",
    "assert (4,) == linear.b.shape\n",
    "\n",
    "x = torch.tensor([[1., 2, 3], [4, 5, 6]])\n",
    "a = linear.forward(x)\n",
    "assert (2, 4) == a.shape\n",
    "\n",
    "dz = torch.tensor([[1., 1, 1, 1], [2., 2, 2, 2]])\n",
    "dx = linear.backward(dz)\n",
    "assert (2, 3) == dx.shape\n",
    "assert (4, 3) == linear.dw.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656e7383-adf3-4822-9d99-644b9eb33e07",
   "metadata": {},
   "source": [
    "### Activation Function\n",
    "\n",
    "__Sigmoid__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "ae86ae0a-0382-4349-acb9-6b1e29be36ac",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-04-08T14:45:23.476995Z",
     "start_time": "2024-04-08T14:45:23.475181Z"
    }
   },
   "outputs": [],
   "source": [
    "class SigmoidActivation():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.z = None\n",
    "\n",
    "    def forward(self, z):\n",
    "        self.z = z\n",
    "        return 1 / (1 + torch.exp(-z))\n",
    "\n",
    "    def backward(self, da):\n",
    "        return da * self.forward(self.z) * (1 - self.forward(self.z))\n",
    "\n",
    "    def update(self, lr):\n",
    "        # no update needed for activation function\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d949cda-b92b-4c17-a868-73dec9fd1718",
   "metadata": {},
   "source": [
    "### Model\n",
    "\n",
    "Now implement an MLP as a succession of layers - linear layers and non-linear activation layers.\n",
    "For creating an instance, you will pass the following arguments: \n",
    "* nx: number of input features\n",
    "* nunits: list of number of units in the hidden layers including the output layer\n",
    "\n",
    "Add a list of layers as member variable.\n",
    "\n",
    "Use just a linear layer at the end. Further below we will use a CE loss which is based on the finally output logit values (see lecture of week 2) where the softmax probabilities are implicit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "ee66c47a-d587-47af-8d10-384a157948f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T14:45:23.479810Z",
     "start_time": "2024-04-08T14:45:23.477686Z"
    }
   },
   "outputs": [],
   "source": [
    "class MLP():\n",
    "\n",
    "    def __init__(self, nx, nunits):\n",
    "        self.nx = nx\n",
    "        self.nlayers = len(nunits)\n",
    "        self.nunits = nunits\n",
    "        self.nunits.insert(0, nx)\n",
    "        self.nclasses = self.nunits[-1]\n",
    "        self.layers = []\n",
    "\n",
    "        for i in range(self.nlayers):\n",
    "            self.layers.append(LinearLayer(self.nunits[i], self.nunits[i + 1]))\n",
    "            if i < self.nlayers - 1:\n",
    "                self.layers.append(SigmoidActivation())\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x - input tensor        \n",
    "        returns output tensor of the model\n",
    "        \"\"\"\n",
    "        for layer in self.layers:\n",
    "            x = layer.forward(x)\n",
    "        return x\n",
    "\n",
    "    def backward(self, dy):\n",
    "        \"\"\"\n",
    "        dy - derivative w.r.t. output tensor\n",
    "        \n",
    "        returns derivative with respect to the input tensor of the model; \n",
    "        on the fly compute all the derivatives w.r.t. parameters of the model\n",
    "        \"\"\"\n",
    "        for layer in reversed(self.layers):\n",
    "            dy = layer.backward(dy)\n",
    "        return dy\n",
    "\n",
    "    def update(self, lr):\n",
    "        \"\"\"\n",
    "        Update the parameters with the given (stored) derivatives w.r.t. model parameters by using the given learning rate. \n",
    "        \"\"\"\n",
    "        for layer in self.layers:\n",
    "            layer.update(lr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0859db-1d16-4652-8549-b09fa695602b",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">SHAPE TEST:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "6020ece6-ccfe-4242-b72c-4d00c0c1f07e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T14:45:23.483310Z",
     "start_time": "2024-04-08T14:45:23.480305Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2])\n",
      "a: torch.Size([2, 4])\n"
     ]
    }
   ],
   "source": [
    "nx = 2\n",
    "nunits = [3, 4]\n",
    "mlp = MLP(nx, nunits)\n",
    "assert 3 == len(mlp.layers)\n",
    "\n",
    "x = torch.tensor([[1., 2], [3, 4]])\n",
    "print(x.shape)\n",
    "a = mlp.forward(x)\n",
    "print(f'a: {a.shape}')\n",
    "assert (2, 4) == a.shape\n",
    "\n",
    "da = torch.tensor([[1., 1, 1, 1], [2., 2, 2, 2]])\n",
    "dx = mlp.backward(da)\n",
    "assert (2, 2) == dx.shape\n",
    "\n",
    "nx = 2\n",
    "nunits = [3, 4]\n",
    "mlp = MLP(nx, nunits)\n",
    "assert 3 == len(mlp.layers)\n",
    "\n",
    "x = torch.tensor([[1., 2], [3, 4]])\n",
    "a = mlp.forward(x)\n",
    "assert (2, 4) == a.shape\n",
    "\n",
    "da = torch.tensor([[1., 1, 1, 1], [2., 2, 2, 2]])\n",
    "dx = mlp.backward(da)\n",
    "assert (2, 2) == dx.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08f5f56-97d9-47c3-b0c8-ee3699c2eaca",
   "metadata": {},
   "source": [
    "### Regression Test\n",
    "\n",
    "Create a regression testing that allows you to test your implementation by regressing against the gradients computed by pytorch's autograd.\n",
    "\n",
    "Below you find two functions that may be helpful in \n",
    "1. creating a reference model from the given model - makes sure that in the reference model the exact same initialized parameters are used; furthermore, that teh parameters of the linear layers (w,b) are specified as tensors with `requires_grad=True`. \n",
    "2. comparing the derivatives w.r.t. parameters for model and refmodel. It assumes that for both, model and refmodel, backprop has been executed. For the model, it means that `backward()`has been executed - for the ref model, only `forward` has been executed, but `backward` applied to the output tensor of the refmodel. For the remodel, we use `grad` of the weights and bias tensors, for the model the parameters `dw` and `db` as basis for the comparison.\n",
    "\n",
    "<span style=\"color:red\">Adjust these methods to make them compliant with your model - it uses internals of our implementation.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "3e33f3c4-ab4a-4271-9d5f-39cc9f53ccc4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T14:45:23.486455Z",
     "start_time": "2024-04-08T14:45:23.484114Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_refmodel(model):\n",
    "    refmodel = MLP(model.nx, model.nunits[1:])\n",
    "    for i, layer in enumerate(model.layers):\n",
    "        if isinstance(layer, LinearLayer):\n",
    "            refmodel.layers[i].w = model.layers[i].w.detach().clone()\n",
    "            refmodel.layers[i].w.requires_grad_()\n",
    "            refmodel.layers[i].b = model.layers[i].b.detach().clone()\n",
    "            refmodel.layers[i].b.requires_grad_()\n",
    "    return refmodel\n",
    "\n",
    "\n",
    "def test_params(model, refmodel, digits=8):\n",
    "    for i, layer in enumerate(model.layers):\n",
    "        if isinstance(layer, LinearLayer):\n",
    "            try:\n",
    "                xxref = refmodel.layers[i].w.grad.detach().numpy()\n",
    "                xx = model.layers[i].dw.numpy()\n",
    "                np.testing.assert_array_almost_equal(xx, xxref, decimal=digits, err_msg=\"Error: layer %i\" % i)\n",
    "                xxref = refmodel.layers[i].b.grad.detach().numpy()\n",
    "                xx = model.layers[i].db.numpy()\n",
    "                np.testing.assert_array_almost_equal(xx, xxref, decimal=digits, err_msg=\"Error: layer %i\" % i)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(\"test failed - reason:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3baf6929-9a82-4ec6-94d1-90ccad1752e0",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\"> REGRESSION TEST</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "f80d2e20-4fb6-4ed9-ab7f-670d9aca8b1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T14:45:23.489574Z",
     "start_time": "2024-04-08T14:45:23.486889Z"
    }
   },
   "outputs": [],
   "source": [
    "# inputs\n",
    "nx = 10\n",
    "x = torch.randn(nx).reshape(-1, nx)\n",
    "\n",
    "# model instance\n",
    "nunits = [20, 40, 1]\n",
    "mlp = MLP(nx, nunits)\n",
    "\n",
    "# forward and backward pass\n",
    "z = mlp.forward(x)\n",
    "dz = torch.tensor([1., ]).reshape(-1, 1)\n",
    "dx = mlp.backward(dz)\n",
    "\n",
    "# create ref model\n",
    "mlpref = create_refmodel(mlp)\n",
    "\n",
    "# only use the forward method of the ref model - and apply backward to the output tensor.\n",
    "zref = mlpref.forward(x)\n",
    "zref.backward()\n",
    "\n",
    "# compare the derivatives computed by your model with the grad computed by pytorch's autograd\n",
    "test_params(mlp, mlpref, digits=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468d6187-bbbd-4bf1-ae3f-929342eeb39d",
   "metadata": {},
   "source": [
    "### Cost \n",
    "\n",
    "Use the cross-entropy cost function directly defined on the basis of the logits - which implicitly includes a softmax calculation (see lecture notes of week 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "f26dbc1b-697b-46cd-94de-d78e701921f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T14:45:23.492314Z",
     "start_time": "2024-04-08T14:45:23.490313Z"
    }
   },
   "outputs": [],
   "source": [
    "class CELoss:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def value(self, z, y):\n",
    "        \"\"\"\n",
    "        Calculate the cross-entropy loss given predicted logits z and true labels y.\n",
    "        \n",
    "        Args:\n",
    "        - z (torch.Tensor): Predicted logits of shape (number of samples, number of classes).\n",
    "        - y (torch.Tensor): True labels of shape (number of samples).\n",
    "        \n",
    "        Returns:\n",
    "        - loss (torch.Tensor): Cross-entropy loss.\n",
    "        \"\"\"\n",
    "        # Compute softmax probabilities\n",
    "        softmax_z = torch.softmax(z, dim=1)\n",
    "        \n",
    "        # Index into softmax probabilities to get the predicted probabilities\n",
    "        pred_probs = softmax_z[torch.arange(z.size(0)), y]\n",
    "        \n",
    "        # Calculate cross-entropy loss\n",
    "        loss = -torch.log(pred_probs).mean()\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def derivative(self, z, y):\n",
    "        \"\"\"\n",
    "        Calculate the derivative of cross-entropy loss with respect to predicted logits z.\n",
    "        \n",
    "        Args:\n",
    "        - z (torch.Tensor): Predicted logits of shape (number of samples, number of classes).\n",
    "        - y (torch.Tensor): True labels of shape (number of samples).\n",
    "        \n",
    "        Returns:\n",
    "        - derivative (torch.Tensor): Derivative of cross-entropy loss with respect to z.\n",
    "        \"\"\"\n",
    "        # Compute softmax probabilities\n",
    "        softmax_z = torch.softmax(z, dim=1)\n",
    "        \n",
    "        # Create one-hot encoded labels\n",
    "        one_hot_y = torch.zeros_like(z)\n",
    "        one_hot_y[torch.arange(z.size(0)), y] = 1\n",
    "        \n",
    "        # Calculate derivative of cross-entropy loss\n",
    "        derivative = softmax_z - one_hot_y\n",
    "        \n",
    "        return derivative\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "9e9e731f-7163-4cc9-a5b0-5c2a000ef8d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T14:45:23.495077Z",
     "start_time": "2024-04-08T14:45:23.492758Z"
    }
   },
   "outputs": [],
   "source": [
    "loss = CELoss()\n",
    "ypred = torch.log(torch.tensor([[0.5, 0.4, 0.1], [0.2, 0.1, 0.7]])).reshape(-1, 3)  # -> logits z\n",
    "y = torch.tensor([1, 2]).reshape(-1)\n",
    "np.testing.assert_almost_equal(loss.value(ypred, y), -torch.log(torch.tensor([0.4, 0.7])).sum(), decimal=8)\n",
    "np.testing.assert_array_almost_equal(loss.derivative(ypred, y),\n",
    "                                     torch.tensor([[0.5000, -0.6000, 0.1000], [0.2000, 0.1000, -0.3000]]), decimal=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648ab724-6516-47ec-9aad-8a2a99a1e78f",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "\n",
    "As in previous' week PW. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "da6cb457-1da9-4c14-83c2-345dfe0bf29e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T14:45:23.507756Z",
     "start_time": "2024-04-08T14:45:23.506223Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "b8a76b89-ea2c-4e26-a43d-874ca5b75e04",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T14:45:23.529936Z",
     "start_time": "2024-04-08T14:45:23.508368Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795f7fbd-b5fe-432d-b59e-732154aea809",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Training Loop\n",
    "\n",
    "Implement mini-batch gradient descent training loop. \n",
    "\n",
    "With the implementation of the two methods below you will be able to train and test the MLP:\n",
    "* train_epoch: for training the model over one epoch with per mini-batch updates\n",
    "* test_epoch: for evaluating the test/validation performance per epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "69d69729-6a94-45a6-b6c6-9ecc7d4f2f9c",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-04-08T14:45:23.533693Z",
     "start_time": "2024-04-08T14:45:23.530825Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, loss, dataloader, lr):\n",
    "    \"\"\"\n",
    "    Iterate over the mini-batches of one epoch, compute per mini-batch the forward and backward pass \n",
    "    and update the parameters. Also compute the loss and accuracy as an average over the epoch. \n",
    "    Note that this average includes per mini-batch updated model predictions and parameter updates.\n",
    "    model -- model to be trained\n",
    "    loss -- loss function to be used \n",
    "    dataloader -- data loader that provides mini-batches (from the training set)\n",
    "    lr -- learning rate to be used in the parameter updates     \n",
    "    returns loss, accuracy \n",
    "    \"\"\"\n",
    "    ### YOUR CODE START ###\n",
    "    nsamples = len(dataloader.dataset)\n",
    "    trainloss, correct = 0.0, 0\n",
    "    for X, y in dataloader:\n",
    "        batchsize = X.shape[0]\n",
    "        X = X.view(batchsize, -1)\n",
    "        z = model.forward(X)\n",
    "        batchloss = loss.value(z, y)\n",
    "        trainloss += batchloss.item()\n",
    "        correct += (z.argmax(dim=1) == y).type(torch.float).sum().item()\n",
    "\n",
    "        # Backpropagation\n",
    "        dz = loss.derivative(z, y)\n",
    "        dx = model.backward(dz)\n",
    "        model.update(lr)\n",
    "    trainloss /= nsamples\n",
    "    correct /= nsamples\n",
    "    return trainloss, correct\n",
    "    ### YOUR CODE START ###\n",
    "\n",
    "\n",
    "def test_epoch(model, loss, dataloader):\n",
    "    \"\"\"\n",
    "    Iterate over the mini-batches of one epoch of the test set. Iterates over the mini-batches of the test set.\n",
    "    Estimates loss and accuracy as an average over the test (validation) set. The model is not updates here. \n",
    "    model -- model to be evaluated\n",
    "    loss -- loss function to be evaluated \n",
    "    dataloader -- data loader that provides mini-batches (from the test/validation set)\n",
    "    returns loss, accuracy \n",
    "    \"\"\"\n",
    "    nsamples = len(dataloader.dataset)\n",
    "    testloss, correct = 0.0, 0\n",
    "    for X, y in dataloader:\n",
    "        batchsize = X.shape[0]\n",
    "        X = X.view(batchsize, -1)\n",
    "        z = model.forward(X)\n",
    "        testloss += loss.value(z, y)\n",
    "        correct += (z.argmax(dim=1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    testloss /= nsamples\n",
    "    correct /= nsamples\n",
    "    return testloss, correct\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2c7fe4-5c5f-40d4-a7b2-8f650140094f",
   "metadata": {},
   "source": [
    "### First Simple Check: Overfitting on Single Sample\n",
    "\n",
    "Load an arbitrary mini-batch from the training set. Train the model by using just this mini-batch.\n",
    "This is another test for checking whether your implementation is capable of learning something (see remark in week 2 of the course)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "73f29756-4bba-473e-83e9-17996fe1b07a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T14:45:23.539059Z",
     "start_time": "2024-04-08T14:45:23.534354Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28]) torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "sample_batch, _ = torch.utils.data.random_split(train_data, [64, 60000 - 64])\n",
    "train_loader = DataLoader(sample_batch, batch_size=64,\n",
    "                          shuffle=False)  # shuffling not needed since only one batch is used.\n",
    "\n",
    "sample_x, sample_y = next(iter(train_loader))\n",
    "print(sample_x.shape, sample_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "9c9c8561-8484-48b2-9369-075f076fa983",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-04-08T14:45:23.687932Z",
     "start_time": "2024-04-08T14:45:23.540407Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train Accuracy: 10.9%, Train Loss: 2.904013\n",
      "Epoch: 10, Train Accuracy: 4.7%, Train Loss:      inf\n",
      "Epoch: 20, Train Accuracy: 7.8%, Train Loss:      inf\n",
      "Epoch: 30, Train Accuracy: 12.5%, Train Loss:      inf\n",
      "Epoch: 40, Train Accuracy: 26.6%, Train Loss:      inf\n",
      "Epoch: 50, Train Accuracy: 9.4%, Train Loss:      inf\n",
      "Epoch: 60, Train Accuracy: 14.1%, Train Loss:      inf\n",
      "Epoch: 70, Train Accuracy: 7.8%, Train Loss:      inf\n",
      "Epoch: 80, Train Accuracy: 9.4%, Train Loss:      inf\n",
      "Epoch: 90, Train Accuracy: 9.4%, Train Loss:      inf\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "lr = 1.0\n",
    "mlp = MLP(28 * 28, [100, 10])\n",
    "mseloss = CELoss()\n",
    "trainlosses = []\n",
    "trainaccs = []\n",
    "for t in range(epochs):\n",
    "    trainloss, trainacc = train_epoch(mlp, mseloss, train_loader, lr)\n",
    "    trainlosses.append(trainloss)\n",
    "    trainaccs.append(trainacc)\n",
    "    if t % 10 == 0:\n",
    "        print(f\"Epoch: {t}, Train Accuracy: {(100 * trainacc):>0.1f}%, Train Loss: {trainloss:>8f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "2464995e-355c-4562-8619-7dea93e5d8ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T14:45:23.811985Z",
     "start_time": "2024-04-08T14:45:23.688675Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Text(0.5, 1.0, 'Train Accuracy')"
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1)\n",
    "plt.plot(torch.arange(epochs), trainlosses, \"b-\")\n",
    "plt.title(\"Train Loss\")\n",
    "\n",
    "plt.figure(2)\n",
    "plt.plot(torch.arange(epochs), trainaccs, \"b-\")\n",
    "plt.ylim([0.0, 1])\n",
    "plt.title(\"Train Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d366251-a20b-4aac-bc33-a4c09607078c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Training with all the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "32f164c3-0e81-478d-ac9e-c5770d55075c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T14:45:23.814851Z",
     "start_time": "2024-04-08T14:45:23.812881Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "8ad2ab4f-b355-4fd3-9fad-7f27d3bd3a06",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T14:45:37.365439Z",
     "start_time": "2024-04-08T14:45:23.815512Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train Accuracy: 10.1%, Train Loss:      inf, Test Accuracy: 11.4%, Test Loss:      inf\n",
      "Epoch: 1, Train Accuracy: 11.8%, Train Loss:      inf, Test Accuracy: 15.5%, Test Loss:      inf\n",
      "Epoch: 2, Train Accuracy: 14.6%, Train Loss:      inf, Test Accuracy: 20.6%, Test Loss:      inf\n",
      "Epoch: 3, Train Accuracy: 18.6%, Train Loss:      inf, Test Accuracy: 23.1%, Test Loss:      inf\n",
      "Epoch: 4, Train Accuracy: 23.7%, Train Loss:      inf, Test Accuracy: 29.5%, Test Loss:      inf\n",
      "Epoch: 5, Train Accuracy: 21.3%, Train Loss:      inf, Test Accuracy: 16.9%, Test Loss:      inf\n",
      "Epoch: 6, Train Accuracy: 21.1%, Train Loss:      inf, Test Accuracy: 19.2%, Test Loss:      inf\n",
      "Epoch: 7, Train Accuracy: 22.2%, Train Loss:      inf, Test Accuracy: 9.7%, Test Loss:      inf\n",
      "Epoch: 8, Train Accuracy: 24.8%, Train Loss:      inf, Test Accuracy: 26.4%, Test Loss:      inf\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[168], line 9\u001B[0m\n\u001B[1;32m      6\u001B[0m trainaccs, testaccs \u001B[38;5;241m=\u001B[39m [], []\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(epochs):\n\u001B[0;32m----> 9\u001B[0m     trainloss, trainacc \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_epoch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmlp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmseloss\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlr\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     10\u001B[0m     testloss, testacc \u001B[38;5;241m=\u001B[39m test_epoch(mlp, mseloss, test_loader)\n\u001B[1;32m     11\u001B[0m     trainlosses\u001B[38;5;241m.\u001B[39mappend(trainloss)\n",
      "Cell \u001B[0;32mIn[163], line 15\u001B[0m, in \u001B[0;36mtrain_epoch\u001B[0;34m(model, loss, dataloader, lr)\u001B[0m\n\u001B[1;32m     13\u001B[0m nsamples \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(dataloader\u001B[38;5;241m.\u001B[39mdataset)\n\u001B[1;32m     14\u001B[0m trainloss, correct \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.0\u001B[39m, \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m---> 15\u001B[0m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mdataloader\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m     16\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatchsize\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshape\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[1;32m     17\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mview\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatchsize\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/TSM_DeLearn-xa9RRjL_/lib/python3.12/site-packages/torch/utils/data/dataloader.py:631\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    628\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    629\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[1;32m    630\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[0;32m--> 631\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    632\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    633\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    634\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    635\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/TSM_DeLearn-xa9RRjL_/lib/python3.12/site-packages/torch/utils/data/dataloader.py:675\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    673\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    674\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m--> 675\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m    676\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[1;32m    677\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/TSM_DeLearn-xa9RRjL_/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:51\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[0;34m(self, possibly_batched_index)\u001B[0m\n\u001B[1;32m     49\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[1;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 51\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     53\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/TSM_DeLearn-xa9RRjL_/lib/python3.12/site-packages/torchvision/datasets/mnist.py:145\u001B[0m, in \u001B[0;36mMNIST.__getitem__\u001B[0;34m(self, index)\u001B[0m\n\u001B[1;32m    142\u001B[0m img \u001B[38;5;241m=\u001B[39m Image\u001B[38;5;241m.\u001B[39mfromarray(img\u001B[38;5;241m.\u001B[39mnumpy(), mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mL\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    144\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransform \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 145\u001B[0m     img \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    147\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarget_transform \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    148\u001B[0m     target \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarget_transform(target)\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/TSM_DeLearn-xa9RRjL_/lib/python3.12/site-packages/torchvision/transforms/transforms.py:137\u001B[0m, in \u001B[0;36mToTensor.__call__\u001B[0;34m(self, pic)\u001B[0m\n\u001B[1;32m    129\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, pic):\n\u001B[1;32m    130\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    131\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[1;32m    132\u001B[0m \u001B[38;5;124;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    135\u001B[0m \u001B[38;5;124;03m        Tensor: Converted image.\u001B[39;00m\n\u001B[1;32m    136\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 137\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_tensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpic\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/TSM_DeLearn-xa9RRjL_/lib/python3.12/site-packages/torchvision/transforms/functional.py:175\u001B[0m, in \u001B[0;36mto_tensor\u001B[0;34m(pic)\u001B[0m\n\u001B[1;32m    173\u001B[0m img \u001B[38;5;241m=\u001B[39m img\u001B[38;5;241m.\u001B[39mpermute((\u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m))\u001B[38;5;241m.\u001B[39mcontiguous()\n\u001B[1;32m    174\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(img, torch\u001B[38;5;241m.\u001B[39mByteTensor):\n\u001B[0;32m--> 175\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mimg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdefault_float_dtype\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdiv\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m255\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    176\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    177\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m img\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "lr = 1.0\n",
    "mlp = MLP(28 * 28, [100, 10])\n",
    "mseloss = CELoss()\n",
    "trainlosses, testlosses = [], []\n",
    "trainaccs, testaccs = [], []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    trainloss, trainacc = train_epoch(mlp, mseloss, train_loader, lr)\n",
    "    testloss, testacc = test_epoch(mlp, mseloss, test_loader)\n",
    "    trainlosses.append(trainloss)\n",
    "    testlosses.append(testloss)\n",
    "    trainaccs.append(trainacc)\n",
    "    testaccs.append(testacc)\n",
    "    print(\n",
    "        f\"Epoch: {epoch}, Train Accuracy: {(100 * trainacc):>0.1f}%, Train Loss: {trainloss:>8f}, Test Accuracy: {(100 * testacc):>0.1f}%, Test Loss: {testloss:>8f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dad1661-b9f4-4048-8196-6b76df0a5925",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.plot(torch.arange(epochs), trainlosses,\"b-\")\n",
    "plt.plot(torch.arange(epochs), testlosses,\"r-\")\n",
    "plt.title(\"CE Loss\")\n",
    "\n",
    "plt.figure(2)\n",
    "plt.plot(torch.arange(epochs), trainaccs,\"b-\")\n",
    "plt.plot(torch.arange(epochs), testaccs,\"r-\")\n",
    "plt.ylim([0.7,1])\n",
    "plt.title(\"Accuracy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060fec40-f14f-4ef0-b795-bbbee1f4776c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
