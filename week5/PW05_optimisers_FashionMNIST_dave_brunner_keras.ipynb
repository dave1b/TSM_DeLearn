{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "G27\n",
    "Dave Brunner"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7fe152be9c0686a4"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import keras\n",
    "import torch\n",
    "from keras import Input\n",
    "import tensorflow as tf\n",
    "from keras.layers import Input, Conv2D, Activation, MaxPool2D, Flatten, Dense\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchsummary import summary\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T18:55:39.388707Z",
     "start_time": "2024-04-02T18:55:32.853601Z"
    }
   },
   "id": "07ec37d7-f7cb-4646-a2dd-9dab66239a30",
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "e2d8a986-1cb2-483b-9bd8-0f71d69fa9e8",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (60000, 28, 28), y_train shape: (60000, 10)\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = keras.datasets.fashion_mnist.load_data() \n",
    "n_classes = 10\n",
    "Y_train = keras.utils.to_categorical(y_train, n_classes)\n",
    "Y_test = keras.utils.to_categorical(y_test, n_classes)\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}, y_train shape: {Y_train.shape}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T18:55:39.507312Z",
     "start_time": "2024-04-02T18:55:39.389532Z"
    }
   },
   "id": "abda488446561a05",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "375ff404-5b8a-4f63-9730-d6708d2ac8d1",
   "metadata": {},
   "source": [
    "### CNN Baseline Model\n",
    "Model with two CNN layers (including max pooling), one dense and an output classification layer, with suitable number of filters and units, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b61b15df-a84b-483d-9365-d8f66390b8bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T18:55:39.551690Z",
     "start_time": "2024-04-02T18:55:39.507998Z"
    }
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    Input(shape=(28, 28, 1)),\n",
    "    Conv2D(filters=32, strides=1, padding='same', kernel_size=4),\n",
    "    Activation(activation='relu'),\n",
    "    MaxPool2D(pool_size=2),\n",
    "    Flatten(),\n",
    "    Dense(10),\n",
    "    Activation('softmax')\n",
    "])\n",
    "model_description = 'Input -> Conv2D filter=32,kernel_s=4, str=1-> ReLU -> MaxPool2D s=2 -> Flatten -> Dense -> Softmax'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4bfd0a4-999c-4690-9ef3-b5ee1ab26c30",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-04-02T18:55:39.560025Z",
     "start_time": "2024-04-02T18:55:39.552909Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "\u001B[1mModel: \"sequential\"\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ conv2d (\u001B[38;5;33mConv2D\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m28\u001B[0m, \u001B[38;5;34m28\u001B[0m, \u001B[38;5;34m32\u001B[0m)     │           \u001B[38;5;34m544\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ activation (\u001B[38;5;33mActivation\u001B[0m)         │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m28\u001B[0m, \u001B[38;5;34m28\u001B[0m, \u001B[38;5;34m32\u001B[0m)     │             \u001B[38;5;34m0\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d (\u001B[38;5;33mMaxPooling2D\u001B[0m)    │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m14\u001B[0m, \u001B[38;5;34m14\u001B[0m, \u001B[38;5;34m32\u001B[0m)     │             \u001B[38;5;34m0\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ flatten (\u001B[38;5;33mFlatten\u001B[0m)               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m6272\u001B[0m)           │             \u001B[38;5;34m0\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (\u001B[38;5;33mDense\u001B[0m)                   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m10\u001B[0m)             │        \u001B[38;5;34m62,730\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ activation_1 (\u001B[38;5;33mActivation\u001B[0m)       │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m10\u001B[0m)             │             \u001B[38;5;34m0\u001B[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">544</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6272</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">62,730</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m63,274\u001B[0m (247.16 KB)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">63,274</span> (247.16 KB)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m63,274\u001B[0m (247.16 KB)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">63,274</span> (247.16 KB)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "\n",
    "\n",
    "class Result:\n",
    "    def __init__(self, network, epoch: int, batch_size: int, train_accuracy: [float], val_accuracy: [float],\n",
    "                 train_loss: [float], val_loss: [float], cm: any):\n",
    "        self.network = network,\n",
    "        self.epoch = epoch,\n",
    "        self.batch_size = batch_size\n",
    "        self.train_loss = train_loss\n",
    "        self.val_loss = val_loss\n",
    "        self.train_accuracy = train_accuracy\n",
    "        self.val_accuracy = val_accuracy\n",
    "        self.cm = cm\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'Network: {self.network}, Epochs: {self.epoch}, Batch size: {self.batch_size}, Final accuracy: [train:{self.train_accuracy[-1]}, val:{self.val_accuracy[-1]}] Final loss: [train:{self.train_loss[-1]}, val:{self.val_loss[-1]}'\n",
    "\n",
    "    def title(self):\n",
    "        return f'Network: {self.network}, Epochs: {self.epoch}, Batch: {self.batch_size}'\n",
    "\n",
    "    def plot(self, plot_cm):\n",
    "        f = plt.figure(figsize=(12, 4))\n",
    "        ax1 = f.add_subplot(121)\n",
    "        ax2 = f.add_subplot(122)\n",
    "        ax1.plot(self.train_loss, label='Training loss')\n",
    "        ax1.plot(self.val_loss, label='Validation loss')\n",
    "        ax1.legend()\n",
    "        ax1.grid()\n",
    "        ax2.plot(self.train_accuracy, label='Training acc')\n",
    "        ax2.plot(self.val_accuracy, label='Validation acc')\n",
    "        ax2.legend()\n",
    "        ax2.grid()\n",
    "        if plot_cm:\n",
    "            disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "            disp.plot(colorbar=False, cmap='Blues')\n",
    "        plt.show()\n",
    "\n",
    "    def plot_result(self, cm=False):\n",
    "        print(\"--------------------------------------------\")\n",
    "        print(self.title())\n",
    "        print(f\"Final val accuracy: {self.val_accuracy[-1]}\")\n",
    "        self.plot(cm)\n",
    "\n",
    "    def print_results(self):\n",
    "        print(\"--------------------------------------------\")\n",
    "        print(self.title())\n",
    "        print(f\"Train accuracy: {self.train_accuracy[-1]}\")\n",
    "        print(f\"Validation accuracy: {self.val_accuracy[-1]}\")\n",
    "\n",
    "\n",
    "results: [Result] = []"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T18:55:39.954407Z",
     "start_time": "2024-04-02T18:55:39.560545Z"
    }
   },
   "id": "584c30cfd0d9d25c",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training\n",
    "\n",
    "Implement the training / evaluation loop\n",
    "Remember training / validation cost and accuracy per epoch and return them as list."
   ],
   "metadata": {},
   "id": "c3fa393a-9f99-48f4-996d-cf8d2a3b8cd5"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (2629956859.py, line 42)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  Cell \u001B[0;32mIn[6], line 42\u001B[0;36m\u001B[0m\n\u001B[0;31m    if verbose:\u001B[0m\n\u001B[0m    ^\u001B[0m\n\u001B[0;31mIndentationError\u001B[0m\u001B[0;31m:\u001B[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "def train_eval(model: keras.Model, optimizer, nepochs, training_loader, validation_loader, scheduler=None, verbose=False):\n",
    "    \"\"\"\n",
    "    Perform training and evaluation loop.\n",
    "    :param model: Model to be trained\n",
    "    :param optimizer: Optimiser to use for training\n",
    "    :param nepochs: Number of epochs\n",
    "    :param training_loader: Loader to provide mini-batches of training samples\n",
    "    :param validation_loader: Loader to provide mini-batches of validation samples\n",
    "    :param scheduler: Scheduler used for a learning rate schedule\n",
    "    :return: Lists with training and validation cost and accuracy per epoch.\n",
    "    \"\"\"\n",
    "    cost_hist = []\n",
    "    cost_hist_val = []\n",
    "    acc_hist = []\n",
    "    acc_hist_val = []\n",
    "\n",
    "    cost_ce = keras.losses.CategoricalCrossentropy()\n",
    "    model.compile(loss=cost_ce, optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    for epoch in range(nepochs):\n",
    "        acc, cost = 0, 0\n",
    "        acc_val, cost_val = 0, 0\n",
    "        batch_count = 0\n",
    "       \n",
    "        for (train_x, train_y), (val_x, val_y) in zip(training_loader.as_numpy_iterator(), validation_loader.as_numpy_iterator()):\n",
    "            # Train on batch\n",
    "            train_metrics = model.train_on_batch(train_x, train_y)\n",
    "            cost += train_metrics[0]\n",
    "            acc += train_metrics[1]\n",
    "\n",
    "            # Validate on batch\n",
    "            val_metrics = model.test_on_batch(val_x, val_y)\n",
    "            cost_val += val_metrics[0]\n",
    "            acc_val += val_metrics[1]\n",
    "            batch_count += 1\n",
    "            \n",
    "        cost_hist.append(cost / batch_count)\n",
    "        acc_hist.append(acc / batch_count)\n",
    "        cost_hist_val.append(cost_val / batch_count)\n",
    "        acc_hist_val.append(acc_val / batch_count)\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"Epoch {epoch + 1}\")\n",
    "                print(f\"Train:      Accuracy={acc_hist[-1]:.4f}, Cost: {cost_hist[-1]:.4f}\")\n",
    "                print(f\"Validation: Accuracy={acc_hist_val[-1]:.4f}, Cost: {cost_hist_val[-1]:.4f}\")\n",
    "                print(\"--------------------------------------\")\n",
    "        if not verbose:\n",
    "            print(f\"Final Validation Accuracy={acc_hist_val[-1]:.4f} Cost: {cost_hist_val[-1]:.4f}\")\n",
    "            print(f\"Final Training   Accuracy={acc_hist[-1]:.4f} Cost: {cost_hist[-1]:.4f}\")\n",
    "\n",
    "    return cost_hist, cost_hist_val, acc_hist, acc_hist_val"
   ],
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-04-02T18:55:39.958148Z",
     "start_time": "2024-04-02T18:55:39.955Z"
    }
   },
   "id": "172c91d1-4c9e-413a-bfff-01f51a1e323a",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "n_epochs = 5\n",
    "batch_size = 64\n",
    "lr = 0.01\n",
    "training_loader = tf.data.Dataset.from_tensor_slices((X_train, Y_train)).batch(batch_size)\n",
    "validation_loader = tf.data.Dataset.from_tensor_slices((X_test, Y_test)).batch(batch_size)\n",
    "\n",
    "optimizer = keras.optimizers.SGD(learning_rate=lr)\n",
    "cost_hist, cost_hist_test, acc_hist, acc_hist_test = train_eval(model, optimizer, n_epochs, training_loader,\n",
    "                                                                validation_loader, verbose=True)\n",
    "results.append(Result(model_description, n_epochs, batch_size, acc_hist, acc_hist_test, cost_hist, cost_hist_test, None))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f4d6d0b5d4314560",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "bacd328c",
   "metadata": {},
   "source": [
    "### Train Baseline CNN Model\n",
    "\n",
    "Follow the \"Steps to Test and Tune a Model\" as presented in the lecture.\n",
    "\n",
    "Train the baseline with SGD without momentum and fixed learning rate. Tune the learning rate by this procedure.\n",
    "\n",
    "Determine a suitable number of epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Overfit on small dataset to see if model is capable of learning"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eab093c3b03e3e41"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "batch_size = 64\n",
    "sample_size = 250\n",
    "\n",
    "lr = 0.01\n",
    "training_loader = tf.data.Dataset.from_tensor_slices((X_train[:sample_size,:,:], Y_train[:sample_size])).batch(batch_size)\n",
    "validation_loader = tf.data.Dataset.from_tensor_slices((X_test, Y_test)).batch(batch_size)\n",
    "\n",
    "optimizer = keras.optimizers.SGD(learning_rate=lr)\n",
    "cost_hist, cost_hist_test, acc_hist, acc_hist_test = train_eval(model, optimizer, n_epochs, training_loader,\n",
    "                                                                validation_loader, verbose=False)\n",
    "results.append(Result(model_description, n_epochs, batch_size, acc_hist, acc_hist_test, cost_hist, cost_hist_test, None))\n",
    "results[-1].plot_result()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3d9717ac",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "532d2c36",
   "metadata": {},
   "source": [
    "### Cross-Validation\n",
    "\n",
    "Use 5-fold cross validation to estimate the accuracy and an error bar of the accuracy estimate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa20d275",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4625a52b-a332-4844-8d7d-6998893a2d70",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Analyse Different Optimisers with different Settings \n",
    "\n",
    "Use the code above to explore different settings for the different optimizers. Use batchsize 64.\n",
    "\n",
    "1. *SGD*: Refer to the results from above - for later comparison.\n",
    "<br>\n",
    "\n",
    "2. *Momentum*: Play with at least three different settings when using momentum: learning rate, momentum parameter, Nesterov flag. Start with momentum=0.9 without Nesterov and suitable learning rate, then vary the momentum parameter and independently the learning rate. Can you see an impact of using Nesterov? What is your recommended best choice (lr, momentum, nesterov, nepochs) for the given problem?\n",
    "<br>\n",
    "\n",
    "3. *RMSProp*: Same thing now for RMSprop (without momentum). Play with at least three different settings when using RMSprop: lr, alpha. Start with the default settings of pytorch with (lr=0.01, alpha=0.99,centered=False). Then vary alpha and independently the learning rate. Can you see an impact when using centered=True? What is your recommended best choice (learning rate, alpha, centered, nepochs) for the given problem?<br>\n",
    "<br>\n",
    "\n",
    "4. *Adam*: Same thing now for Adam. Play with at least three different settings. Start with the default settings of pytorch. What is your recommended best choice for the given problem?<br>\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fa1c2b-50d7-4b23-91c8-c47eec5fc8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbatch = 64\n",
    "nepochs =\n",
    "\n",
    "training_loader = DataLoader(training_data, batch_size=nbatch, shuffle=True)\n",
    "validation_loader = DataLoader(validation_data, batch_size=nbatch, shuffle=True)\n",
    "\n",
    "model = mlp()\n",
    "optimizer = ...\n",
    "cost_hist, cost_hist_test, acc_hist, acc_hist_test = train_eval(model, optimizer, nepochs, training_loader,\n",
    "                                                                validation_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f24c35-9def-48ba-a505-20b99d450584",
   "metadata": {},
   "source": [
    "### Plots and Comments (for the different steps described above) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1ab6cb-7787-4f18-8763-ae231c610c68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "35fb4db4",
   "metadata": {},
   "source": [
    "### Learning Rate Schedule\n",
    "\n",
    "Modify your `train_eval` method implemented above to support using a learning rate schedule for SGD (without momentum) - by using e.g. StepLR. What are your preferred settings for the given task?\n",
    "\n",
    "Compare and evaluate the training performance with the results obtained for the different optimizers above and provide a judgement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79a02fc",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d237b4",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
